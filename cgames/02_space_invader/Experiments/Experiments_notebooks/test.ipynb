{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import gym\n",
    "import random\n",
    "import torch\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import sys\n",
    "import os\n",
    "from Manifold_Analysis import Manifold_analysis\n",
    "sys.path.append('../../../')\n",
    "from algos.agents import A2CAgent\n",
    "from algos.models.actor_critic_cnn import ActorCnn, CriticCnn\n",
    "from algos.models.actor_critic_cnn_init import ActorCnn_init, CriticCnn_init\n",
    "from algos.preprocessing.stack_frame import preprocess_frame, stack_frame\n",
    "\n",
    "# importing required libraries\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.decomposition import PCA, IncrementalPCA\n",
    "from sklearn.manifold import MDS\n",
    "from sklearn.manifold import Isomap\n",
    "from sklearn.metrics import pairwise_distances\n",
    "\n",
    "from matplotlib.ticker import NullFormatter\n",
    "from collections import OrderedDict\n",
    "from functools import partial\n",
    "from sklearn import manifold, datasets\n",
    "\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device:  cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A.L.E: Arcade Learning Environment (version +978d2ce)\n",
      "[Powered by Stella]\n"
     ]
    }
   ],
   "source": [
    "# if gpu is to be used\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device: \", device)\n",
    "\n",
    "#env = gym.make('SpaceInvaders-v0',render_mode='human')\n",
    "env = gym.make('SpaceInvaders-v0')\n",
    "\n",
    "\n",
    "env.seed(0)\n",
    "\n",
    "def stack_frames(frames, state, is_new=False):\n",
    "    frame = preprocess_frame(state, (8, -12, -12, 4), 84)\n",
    "    frames = stack_frame(frames, frame, is_new)\n",
    "\n",
    "    return frames\n",
    "    \n",
    "\n",
    "INPUT_SHAPE = (4, 84, 84)\n",
    "ACTION_SIZE = env.action_space.n\n",
    "SEED =0\n",
    "GAMMA =0.99           # discount factor\n",
    "ALPHA=0.0001          # Actor learning rate\n",
    "BETA =0.0005          # Critic learning rate\n",
    "UPDATE_EVERY = 100     # how often to update the network \n",
    "\n",
    "\n",
    "epsilon_by_epsiode = lambda frame_idx: EPS_END + (EPS_START - EPS_END) * math.exp(-1. * frame_idx /EPS_DECAY)\n",
    "\n",
    "start_epoch =0\n",
    "scores = []\n",
    "scores_window = deque(maxlen=20)\n",
    "length_trial = 500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOAD INIT MODEL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOAD HOOKS MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_model(model_init,model_hooks,PATH):\n",
    "    G = []\n",
    "    for param_tensor in model_hooks.actor_net.state_dict():\n",
    "        G.append(param_tensor)\n",
    "    H = []\n",
    "    for param_tensor in model_hooks.critic_net.state_dict():\n",
    "        H.append(param_tensor)\n",
    "\n",
    "    i =0\n",
    "    for param_tensor in model_init.actor_net.state_dict():\n",
    "        model_hooks.actor_net.state_dict()[G[i]].data.copy_(model_init.actor_net.state_dict()[param_tensor])\n",
    "        i+=1\n",
    "    i =0\n",
    "    for param_tensor in model_init.critic_net.state_dict():\n",
    "        model_hooks.critic_net.state_dict()[H[i]].data.copy_(model_init.critic_net.state_dict()[param_tensor])\n",
    "        i+=1\n",
    "    \n",
    "    torch.save({\n",
    "            'epoch':0,\n",
    "            'modelA_state_dict': model_hooks.actor_net.state_dict(),\n",
    "            'modelB_state_dict': model_hooks.critic_net.state_dict(),\n",
    "            'optimizerA_state_dict': model_hooks.actor_optimizer.state_dict(),\n",
    "            'optimizerB_state_dict': model_hooks.critic_optimizer.state_dict(),\n",
    "            'Score':0,\n",
    "            }, PATH)\n",
    "    \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_0 = A2CAgent(INPUT_SHAPE, ACTION_SIZE, SEED, device, GAMMA, ALPHA, BETA, UPDATE_EVERY, ActorCnn, CriticCnn)\n",
    "agent_0_init = A2CAgent(INPUT_SHAPE, ACTION_SIZE, SEED, device, GAMMA, ALPHA, BETA, UPDATE_EVERY, ActorCnn_init, CriticCnn_init)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/charlottebeylier/Documents/PhD/Atari1.0/Reinforcement-Learning_modif/cgames/02_space_invader/Analysis/Models_training_a2c_space_invader/model_a2c_0_2.pt\n"
     ]
    }
   ],
   "source": [
    "a = \"model_a2c_0_2\"\n",
    "PATH = os.path.join(os.getcwd(),\"Models_training_a2c_space_invader\",a+ \".pt\")\n",
    "print(PATH)\n",
    "checkpoint = torch.load(PATH , map_location=torch.device('cpu'))\n",
    "agent_0_init.actor_net.load_state_dict(checkpoint['modelA_state_dict'])\n",
    "agent_0_init.critic_net.load_state_dict(checkpoint['modelB_state_dict'])\n",
    "agent_0_init.actor_optimizer.load_state_dict(checkpoint['optimizerA_state_dict'])\n",
    "agent_0_init.critic_optimizer.load_state_dict(checkpoint['optimizerB_state_dict'])\n",
    "\n",
    "\n",
    "\n",
    "agent_0.actor_optimizer.load_state_dict(checkpoint['optimizerA_state_dict'])\n",
    "agent_0.critic_optimizer.load_state_dict(checkpoint['optimizerB_state_dict'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = os.path.join(os.getcwd(),\"Models_training_a2c_space_invader\",\"agent_a2c_0_2\"+ \".pt\")\n",
    "copy_model(agent_0_init,agent_0,PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.0092, -0.0320,  0.0407,  0.0175,  0.0115, -0.0174])\n",
      "tensor([[-0.0305,  0.0434, -0.0298,  ...,  0.0029,  0.0153,  0.0188],\n",
      "        [-0.0114,  0.0372,  0.0164,  ..., -0.0280,  0.0407,  0.0196],\n",
      "        [-0.0099, -0.0288, -0.0011,  ...,  0.0354, -0.0200,  0.0275],\n",
      "        [-0.0239, -0.0246, -0.0034,  ...,  0.0120, -0.0229,  0.0118],\n",
      "        [-0.0032,  0.0082,  0.0427,  ..., -0.0382,  0.0403, -0.0124],\n",
      "        [ 0.0288, -0.0233, -0.0295,  ..., -0.0200, -0.0117, -0.0272]])\n"
     ]
    }
   ],
   "source": [
    "print(agent_0.actor_net.state_dict()['fc2.0.bias'])\n",
    "print(agent_0.actor_net.state_dict()['fc2.0.weight'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.0092, -0.0320,  0.0407,  0.0175,  0.0115, -0.0174])\n",
      "tensor([[-0.0305,  0.0434, -0.0298,  ...,  0.0029,  0.0153,  0.0188],\n",
      "        [-0.0114,  0.0372,  0.0164,  ..., -0.0280,  0.0407,  0.0196],\n",
      "        [-0.0099, -0.0288, -0.0011,  ...,  0.0354, -0.0200,  0.0275],\n",
      "        [-0.0239, -0.0246, -0.0034,  ...,  0.0120, -0.0229,  0.0118],\n",
      "        [-0.0032,  0.0082,  0.0427,  ..., -0.0382,  0.0403, -0.0124],\n",
      "        [ 0.0288, -0.0233, -0.0295,  ..., -0.0200, -0.0117, -0.0272]])\n"
     ]
    }
   ],
   "source": [
    "print(agent_0_init.actor_net.state_dict()['fc.2.bias'])\n",
    "print(agent_0_init.actor_net.state_dict()['fc.2.weight'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model_hooks' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/pl/cllhhs1s23700mfqjt1z6tkr0000gn/T/ipykernel_39945/769828154.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mparam_tensor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactor_net\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model_hooks' is not defined"
     ]
    }
   ],
   "source": [
    "for param_tensor in model_hooks.actor_net.state_dict():\n",
    "    print(param_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3cd8fba5e2a7e5201efd12f596ba02da03390e92eb7b5a4f25cd4f2446eed5e6"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 64-bit ('atari1.0': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
